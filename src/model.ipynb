{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Wine Quality Classification Model\n",
    "\n",
    "In this bonus, we will build a classification model to predict the quality of wine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.90</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>2.049401</td>\n",
       "      <td>0.070574</td>\n",
       "      <td>16.593818</td>\n",
       "      <td>42.27</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.71</td>\n",
       "      <td>8.64</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0.5768</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>3.109590</td>\n",
       "      <td>0.101681</td>\n",
       "      <td>22.555519</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.54</td>\n",
       "      <td>0.5918</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>3.673744</td>\n",
       "      <td>0.072416</td>\n",
       "      <td>9.316866</td>\n",
       "      <td>35.52</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.39</td>\n",
       "      <td>0.4201</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>3.371815</td>\n",
       "      <td>0.072755</td>\n",
       "      <td>18.212300</td>\n",
       "      <td>41.97</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.55</td>\n",
       "      <td>14.07</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.51</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4.404723</td>\n",
       "      <td>0.066379</td>\n",
       "      <td>9.360591</td>\n",
       "      <td>46.27</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           5.90            0.4451       0.1813        2.049401   0.070574   \n",
       "1           8.40            0.5768       0.2099        3.109590   0.101681   \n",
       "2           7.54            0.5918       0.3248        3.673744   0.072416   \n",
       "3           5.39            0.4201       0.3131        3.371815   0.072755   \n",
       "4           6.51            0.5675       0.1940        4.404723   0.066379   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0            16.593818                 42.27   0.9982  3.27       0.71   \n",
       "1            22.555519                 16.01   0.9960  3.35       0.57   \n",
       "2             9.316866                 35.52   0.9990  3.31       0.64   \n",
       "3            18.212300                 41.97   0.9945  3.34       0.55   \n",
       "4             9.360591                 46.27   0.9925  3.27       0.45   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     8.64        7  \n",
       "1    10.03        8  \n",
       "2     9.23        8  \n",
       "3    14.07        9  \n",
       "4    11.49        8  "
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/anggur.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training and Test set\n",
    "\n",
    "We will split the training and test set to determine the performance of a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, stratify=df['quality'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['quality'], axis=1)\n",
    "y_train = train_set['quality']\n",
    "X_test = test_set.drop(['quality'], axis=1)\n",
    "y_test = test_set['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>7.72</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>2.801338</td>\n",
       "      <td>0.091782</td>\n",
       "      <td>20.567663</td>\n",
       "      <td>38.42</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>8.27</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>2.339661</td>\n",
       "      <td>0.063838</td>\n",
       "      <td>8.221410</td>\n",
       "      <td>55.40</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.61</td>\n",
       "      <td>11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>7.49</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>3.177156</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>18.603452</td>\n",
       "      <td>55.58</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5545</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>1.721984</td>\n",
       "      <td>0.089206</td>\n",
       "      <td>21.507712</td>\n",
       "      <td>43.33</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>9.44</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.2622</td>\n",
       "      <td>5.210260</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>24.021371</td>\n",
       "      <td>39.76</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>6.72</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>2.178067</td>\n",
       "      <td>0.085630</td>\n",
       "      <td>15.476538</td>\n",
       "      <td>45.15</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>5.30</td>\n",
       "      <td>0.5220</td>\n",
       "      <td>0.3049</td>\n",
       "      <td>1.130890</td>\n",
       "      <td>0.089340</td>\n",
       "      <td>13.756951</td>\n",
       "      <td>48.34</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>8.18</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>1.693136</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>7.751049</td>\n",
       "      <td>38.81</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>7.40</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>2.798932</td>\n",
       "      <td>0.069678</td>\n",
       "      <td>23.568005</td>\n",
       "      <td>48.41</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.55</td>\n",
       "      <td>13.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>9.29</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>3.404153</td>\n",
       "      <td>0.098335</td>\n",
       "      <td>13.935516</td>\n",
       "      <td>46.79</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "244           7.72            0.5451       0.1264        2.801338   0.091782   \n",
       "917           8.27            0.7417       0.2181        2.339661   0.063838   \n",
       "895           7.49            0.4576       0.2252        3.177156   0.075400   \n",
       "66            7.25            0.5545       0.2535        1.721984   0.089206   \n",
       "331           9.44            0.5490       0.2622        5.210260   0.054500   \n",
       "..             ...               ...          ...             ...        ...   \n",
       "732           6.72            0.4886       0.2933        2.178067   0.085630   \n",
       "547           5.30            0.5220       0.3049        1.130890   0.089340   \n",
       "569           8.18            0.3570       0.1931        1.693136   0.077684   \n",
       "155           7.40            0.4505       0.2401        2.798932   0.069678   \n",
       "52            9.29            0.5590       0.2734        3.404153   0.098335   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "244            20.567663                 38.42   0.9963  3.29       0.72   \n",
       "917             8.221410                 55.40   0.9950  3.29       0.61   \n",
       "895            18.603452                 55.58   0.9922  3.25       0.68   \n",
       "66             21.507712                 43.33   0.9921  3.35       0.46   \n",
       "331            24.021371                 39.76   0.9998  3.25       0.55   \n",
       "..                   ...                   ...      ...   ...        ...   \n",
       "732            15.476538                 45.15   0.9973  3.20       0.51   \n",
       "547            13.756951                 48.34   0.9976  3.32       0.55   \n",
       "569             7.751049                 38.81   0.9952  3.46       0.63   \n",
       "155            23.568005                 48.41   0.9965  3.44       0.55   \n",
       "52             13.935516                 46.79   0.9943  3.22       0.47   \n",
       "\n",
       "     alcohol  \n",
       "244    10.56  \n",
       "917    11.20  \n",
       "895     8.97  \n",
       "66     11.19  \n",
       "331    10.97  \n",
       "..       ...  \n",
       "732    13.87  \n",
       "547    11.32  \n",
       "569    10.11  \n",
       "155    13.58  \n",
       "52     12.66  \n",
       "\n",
       "[800 rows x 11 columns]"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244     8\n",
       "917     9\n",
       "895     7\n",
       "66      8\n",
       "331     9\n",
       "       ..\n",
       "732     9\n",
       "547     8\n",
       "569     8\n",
       "155    10\n",
       "52     10\n",
       "Name: quality, Length: 800, dtype: int64"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>9.37</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.2638</td>\n",
       "      <td>3.430787</td>\n",
       "      <td>0.056311</td>\n",
       "      <td>16.719396</td>\n",
       "      <td>24.74</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>7.90</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.2746</td>\n",
       "      <td>2.791431</td>\n",
       "      <td>0.082855</td>\n",
       "      <td>6.172613</td>\n",
       "      <td>28.34</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>6.82</td>\n",
       "      <td>0.5197</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>2.408717</td>\n",
       "      <td>0.100882</td>\n",
       "      <td>13.210217</td>\n",
       "      <td>41.16</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>8.25</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>1.573458</td>\n",
       "      <td>0.105009</td>\n",
       "      <td>7.389244</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>7.91</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>3.074861</td>\n",
       "      <td>0.123317</td>\n",
       "      <td>15.755803</td>\n",
       "      <td>33.95</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>6.32</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>3.599399</td>\n",
       "      <td>0.069487</td>\n",
       "      <td>11.033585</td>\n",
       "      <td>28.55</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>7.88</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.2887</td>\n",
       "      <td>4.380263</td>\n",
       "      <td>0.055661</td>\n",
       "      <td>21.633450</td>\n",
       "      <td>45.21</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>6.88</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>1.992063</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>9.005354</td>\n",
       "      <td>33.34</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>11.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>7.44</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>3.196452</td>\n",
       "      <td>0.038998</td>\n",
       "      <td>21.260241</td>\n",
       "      <td>34.14</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>5.94</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>2.584408</td>\n",
       "      <td>0.081678</td>\n",
       "      <td>14.324538</td>\n",
       "      <td>31.92</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.59</td>\n",
       "      <td>7.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "643           9.37            0.4153       0.2638        3.430787   0.056311   \n",
       "612           7.90            0.4026       0.2746        2.791431   0.082855   \n",
       "822           6.82            0.5197       0.3358        2.408717   0.100882   \n",
       "982           8.25            0.5035       0.2690        1.573458   0.105009   \n",
       "588           7.91            0.6452       0.2551        3.074861   0.123317   \n",
       "..             ...               ...          ...             ...        ...   \n",
       "748           6.32            0.4472       0.2593        3.599399   0.069487   \n",
       "957           7.88            0.4736       0.2887        4.380263   0.055661   \n",
       "884           6.88            0.4912       0.2175        1.992063   0.082524   \n",
       "688           7.44            0.6484       0.2596        3.196452   0.038998   \n",
       "170           5.94            0.5876       0.2906        2.584408   0.081678   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "643            16.719396                 24.74   0.9979  3.38       0.54   \n",
       "612             6.172613                 28.34   0.9987  3.27       0.54   \n",
       "822            13.210217                 41.16   0.9958  3.17       0.56   \n",
       "982             7.389244                 38.75   0.9956  3.42       0.66   \n",
       "588            15.755803                 33.95   0.9992  3.28       0.50   \n",
       "..                   ...                   ...      ...   ...        ...   \n",
       "748            11.033585                 28.55   0.9955  3.19       0.56   \n",
       "957            21.633450                 45.21   0.9963  3.30       0.52   \n",
       "884             9.005354                 33.34   0.9966  3.50       0.71   \n",
       "688            21.260241                 34.14   0.9962  3.38       0.62   \n",
       "170            14.324538                 31.92   0.9935  3.24       0.59   \n",
       "\n",
       "     alcohol  \n",
       "643    12.41  \n",
       "612    11.16  \n",
       "822     8.96  \n",
       "982    10.48  \n",
       "588    12.20  \n",
       "..       ...  \n",
       "748    12.40  \n",
       "957     9.18  \n",
       "884    11.31  \n",
       "688     7.19  \n",
       "170     7.82  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643    10\n",
       "612     8\n",
       "822     7\n",
       "982     8\n",
       "588     9\n",
       "       ..\n",
       "748     9\n",
       "957     8\n",
       "884     8\n",
       "688     6\n",
       "170     6\n",
       "Name: quality, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this section, we will process the data before feeding it into a classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1000 non-null   float64\n",
      " 1   volatile acidity      1000 non-null   float64\n",
      " 2   citric acid           1000 non-null   float64\n",
      " 3   residual sugar        1000 non-null   float64\n",
      " 4   chlorides             1000 non-null   float64\n",
      " 5   free sulfur dioxide   1000 non-null   float64\n",
      " 6   total sulfur dioxide  1000 non-null   float64\n",
      " 7   density               1000 non-null   float64\n",
      " 8   pH                    1000 non-null   float64\n",
      " 9   sulphates             1000 non-null   float64\n",
      " 10  alcohol               1000 non-null   float64\n",
      " 11  quality               1000 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 93.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values to be handled."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Target Variable\n",
    "\n",
    "The values in the target variable range from 5 to 10, which may work for some classification models but other models may require the target variable to have values starting from 0 and incrementing by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data\n",
    "\n",
    "The data to be trained is relatively small, therefore we will perform resampling to balance the class distribution, then generate synthetic data using augmentation with Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Perform oversampling to balance the classes\n",
    "y_counts = np.bincount(y_train)\n",
    "min_sample = np.min(y_counts[np.nonzero(y_counts)]) - 1\n",
    "sm = SMOTE(random_state=42, k_neighbors=min_sample)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the standard deviation of the Gaussian noise to add\n",
    "std_dev = 0.1\n",
    "\n",
    "# Generate new data points with Gaussian noise added\n",
    "n_iter = 5\n",
    "fold = len(X_train)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    for j in range(fold):\n",
    "        synthetic_data = X_train.iloc[j].values + np.random.normal(loc=0, scale=std_dev, size=X_train.shape[1])\n",
    "        synthetic_data_df = pd.DataFrame(synthetic_data.reshape(1, -1), columns=X_train.columns)\n",
    "        X_train = pd.concat([X_train, synthetic_data_df], axis=0)\n",
    "        y_train = np.append(y_train, y_train[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12924 12924\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "In this section, we aim to perform feature scaling by transforming the numerical columns of our data into a normal standard distribution. The purpose of this transformation is to make the data comparable across different features, as well as to improve the performance of linear-based classification models. This way, the classifiers can more effectively recognize patterns in the data and make accurate predictions, regardless of the range of values in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6508553 ,  0.22116508, -1.36115963, ...,  0.04376549,\n",
       "         0.98052311,  0.22693379],\n",
       "       [ 1.05054744,  1.67618347, -0.46465626, ...,  0.04376549,\n",
       "         0.1428833 ,  0.48728043],\n",
       "       [ 0.48371131, -0.42641432, -0.39524324, ..., -0.2500715 ,\n",
       "         0.67592682, -0.41986489],\n",
       "       ...,\n",
       "       [ 0.1444766 , -1.3820829 , -0.1686155 , ..., -0.78387294,\n",
       "         1.70821381,  1.70560842],\n",
       "       [ 0.75620467,  1.63778712, -1.41021028, ..., -0.01811131,\n",
       "         0.19981156,  1.39362231],\n",
       "       [ 1.41061112, -0.33480214,  1.09559882, ..., -0.59310825,\n",
       "         0.55410014,  0.81617185]])"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.84993173, -0.7394727 , -0.01787105, ...,  0.70489872,\n",
       "        -0.39016022,  0.9794983 ],\n",
       "       [ 0.78166364, -0.83346422,  0.08771495, ..., -0.103153  ,\n",
       "        -0.39016022,  0.47100877],\n",
       "       [-0.00318639,  0.03318203,  0.68603562, ..., -0.83774547,\n",
       "        -0.23786207, -0.42393281],\n",
       "       ...,\n",
       "       [ 0.04041639, -0.17774383, -0.47052215, ...,  1.58640968,\n",
       "         0.90437404,  0.53202751],\n",
       "       [ 0.44737566,  0.98567881, -0.05893228, ...,  0.70489872,\n",
       "         0.21903237, -1.14395398],\n",
       "       [-0.64269382,  0.53570364,  0.24413865, ..., -0.32353074,\n",
       "        -0.00941485, -0.88767526]])"
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Classifiers\n",
    "\n",
    "In this section, we will fit multiple models to the processed training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-125 {color: black;background-color: white;}#sk-container-id-125 pre{padding: 0;}#sk-container-id-125 div.sk-toggleable {background-color: white;}#sk-container-id-125 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-125 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-125 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-125 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-125 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-125 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-125 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-125 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-125 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-125 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-125 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-125 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-125 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-125 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-125 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-125 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-125 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-125 div.sk-item {position: relative;z-index: 1;}#sk-container-id-125 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-125 div.sk-item::before, #sk-container-id-125 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-125 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-125 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-125 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-125 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-125 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-125 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-125 div.sk-label-container {text-align: center;}#sk-container-id-125 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-125 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-125\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-154\" type=\"checkbox\" checked><label for=\"sk-estimator-id-154\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=10000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-126 {color: black;background-color: white;}#sk-container-id-126 pre{padding: 0;}#sk-container-id-126 div.sk-toggleable {background-color: white;}#sk-container-id-126 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-126 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-126 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-126 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-126 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-126 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-126 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-126 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-126 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-126 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-126 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-126 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-126 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-126 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-126 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-126 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-126 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-126 div.sk-item {position: relative;z-index: 1;}#sk-container-id-126 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-126 div.sk-item::before, #sk-container-id-126 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-126 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-126 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-126 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-126 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-126 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-126 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-126 div.sk-label-container {text-align: center;}#sk-container-id-126 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-126 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-126\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-155\" type=\"checkbox\" checked><label for=\"sk-estimator-id-155\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-127 {color: black;background-color: white;}#sk-container-id-127 pre{padding: 0;}#sk-container-id-127 div.sk-toggleable {background-color: white;}#sk-container-id-127 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-127 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-127 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-127 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-127 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-127 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-127 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-127 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-127 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-127 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-127 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-127 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-127 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-127 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-127 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-127 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-127 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-127 div.sk-item {position: relative;z-index: 1;}#sk-container-id-127 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-127 div.sk-item::before, #sk-container-id-127 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-127 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-127 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-127 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-127 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-127 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-127 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-127 div.sk-label-container {text-align: center;}#sk-container-id-127 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-127 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-127\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-156\" type=\"checkbox\" checked><label for=\"sk-estimator-id-156\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-128 {color: black;background-color: white;}#sk-container-id-128 pre{padding: 0;}#sk-container-id-128 div.sk-toggleable {background-color: white;}#sk-container-id-128 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-128 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-128 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-128 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-128 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-128 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-128 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-128 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-128 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-128 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-128 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-128 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-128 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-128 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-128 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-128 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-128 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-128 div.sk-item {position: relative;z-index: 1;}#sk-container-id-128 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-128 div.sk-item::before, #sk-container-id-128 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-128 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-128 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-128 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-128 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-128 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-128 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-128 div.sk-label-container {text-align: center;}#sk-container-id-128 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-128 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-128\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(max_iter=10000,\n",
       "                                                 random_state=42)),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-157\" type=\"checkbox\" ><label for=\"sk-estimator-id-157\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(max_iter=10000,\n",
       "                                                 random_state=42)),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-158\" type=\"checkbox\" ><label for=\"sk-estimator-id-158\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-159\" type=\"checkbox\" ><label for=\"sk-estimator-id-159\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(max_iter=10000,\n",
       "                                                 random_state=42)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote = VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42, max_iter=10000)), \n",
    "                                    ('xgb', XGBClassifier())], voting='hard')\n",
    "vote.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section, we will determine the performance of each model towards the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.91      0.98      0.94        50\n",
      "           3       0.96      0.81      0.88        90\n",
      "           4       0.76      0.86      0.81        44\n",
      "           5       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.78      0.92      0.83       200\n",
      "weighted avg       0.89      0.88      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.60      0.75      0.67         8\n",
      "           2       0.87      0.82      0.85        50\n",
      "           3       0.88      0.86      0.87        90\n",
      "           4       0.81      0.86      0.84        44\n",
      "           5       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.67      0.69      0.68       200\n",
      "weighted avg       0.84      0.84      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_svc = svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svc, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      0.75      0.80         8\n",
      "           2       0.92      0.90      0.91        50\n",
      "           3       0.86      0.87      0.86        90\n",
      "           4       0.76      0.80      0.78        44\n",
      "           5       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.70      0.67      0.69       200\n",
      "weighted avg       0.85      0.84      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.91      0.98      0.94        50\n",
      "           3       0.90      0.87      0.88        90\n",
      "           4       0.79      0.77      0.78        44\n",
      "           5       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.87       200\n",
      "   macro avg       0.80      0.87      0.82       200\n",
      "weighted avg       0.87      0.87      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_vote = vote.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_vote, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting multiple trials, we can conclude that the **Logistic Regression model outperformed other models on the test data**. This could be attributed to the strong correlation between the `alcohol` feature and the target variable, where the average `alcohol` values for each class showed a linear relationship with the target variable. Logistic Regression is particularly suitable for datasets with linear relationships between input and output variables, which could explain why it performed the best in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
